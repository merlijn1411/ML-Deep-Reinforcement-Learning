behaviors:
  Seeker:
    trainer_type: ppo
    keep_checkpoints: 5
    checkpoint_interval: 500000
    max_steps: 1000000
    threaded: true
    time_horizon: 64
    summary_freq: 5000

    hyperparameters:
      batch_size:   1024 
      buffer_size:  10240 
      learning_rate: 0.0003
      beta: 0.003
      epsilon: 0.15
      lambd: 0.95
      num_epoch: 4
      learning_rate_schedule: constant
      beta_schedule: constant
      epsilon_schedule: constant

    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
      encoding_size: 64
      memory:
        sequence_length: 64
        memory_size: 256

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

      curiosity:
        gamma: 0.995
        strength: 0.01
        learning_rate: 3e-4
    
    self_play: 
      save_steps: 20000
      swap_steps: 10000
      play_against_latest_model_ratio: 0.5
      initial_elo:  600.0
      log_path: "results"
  
  Runner:
    trainer_type: ppo
    keep_checkpoints: 5
    checkpoint_interval: 500000
    max_steps: 1000000
    threaded: true
    time_horizon: 64
    summary_freq: 5000

    hyperparameters:
      batch_size:   2048 
      buffer_size:  20480 
      learning_rate: 0.0003
      beta: 0.003
      epsilon: 0.15
      lambd: 0.95
      num_epoch: 4
      learning_rate_schedule: constant
      beta_schedule: constant
      epsilon_schedule: constant

    network_settings:
      normalize: true
      hidden_units: 254
      num_layers: 3
      vis_encode_type: simple
      encoding_size: 64
      memory:
        sequence_length: 64
        memory_size: 256

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

      curiosity:
        gamma: 0.995
        strength: 0.01
        learning_rate: 3e-4
    
    self_play: 
      save_steps: 20000
      swap_steps: 10000
      play_against_latest_model_ratio: 0.5
      initial_elo:  600.0
      log_path: "results"

environment_parameters:
  TrainingArea_Seeker:
    curriculum:
      - name: Easy
        completion_criteria:
          measure: reward
          behavior: "Seeker"
          signal_smoothing: true
          min_lesson_length: 2
          threshold: 0.75
          parameters: {
            block_distance: 2
          }
        value: 0.2

      - name: Medium
        completion_criteria:
          measure: reward
          behavior: "Seeker"
          signal_smoothing: true
          min_lesson_length: 4
          threshold: 0.90
          parameters: {
            block_distance: 4
          }
        value: 0.6

      - name: Hard
        completion_criteria:
          measure: reward
          behavior: "Seeker"
          signal_smoothing: true
          min_lesson_length: 6
          threshold: 1
          parameters: {
            block_distance: 6
          }
        value: 0.9

  TrainingArea_Runner:
    curriculum:
      - name: Easy
        completion_criteria:
          measure: reward
          behavior: "Runner"
          signal_smoothing: true
          min_lesson_length: 2
          threshold: 0.75
          parameters: {
            block_distance: 2
          }
        value: 0.2

      - name: Medium
        completion_criteria:
          measure: reward
          behavior: "Runner"
          signal_smoothing: true
          min_lesson_length: 4
          threshold: 0.90
          parameters: {
            block_distance: 4
          }
        value: 0.6

      - name: Hard
        completion_criteria:
          measure: reward
          behavior: "Runner"
          signal_smoothing: true
          min_lesson_length: 6
          threshold: 1
          parameters: {
            block_distance: 6
          }
        value: 0.9